{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1170c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f85a0a-7311-4dbd-99f6-8ae276318439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e123254-2f14-432b-bb51-6e5c42114459",
   "metadata": {},
   "source": [
    "WITHOUT ADDING FAQs CONTENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b4dfac4-ee81-4012-946c-528aa651bd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You (Customer):  hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Service Agent: Hello! Thank you for reaching out to Piki delivery company. I'd be happy to help you with your inquiry. However, before we proceed, could you please share the order number or any relevant details about your shipment that you're concerned about? That way, I can better assist you and provide a more personalized solution.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You (Customer):  I want to track my order\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Service Agent: I'd be happy to help you with tracking your order!\n",
      "\n",
      "To assist you further, could you please share the order number or any other relevant details you have about your order, such as the recipient's name or the delivery address?\n",
      "\n",
      "Once I have that information, I'll do my best to provide you with an update on the status of your package.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You (Customer):  1348888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Service Agent: Thank you for reaching out to track your order! I'm happy to help.\n",
      "\n",
      "According to our records, the order with ID number 1348888 has been marked as \"Delivery completed by driver\". This means that the package was successfully delivered to the recipient's address.\n",
      "\n",
      "As the status indicates, the delivery process is now complete. If you have any further questions or concerns, please don't hesitate to ask.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You (Customer):  can you have M another details from this order?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Service Agent: I'd be happy to help!\n",
      "\n",
      "However, since you're asking about a specific order (1348888), I'm assuming you're the recipient or someone authorized to receive that package. If that's correct, then yes, I can definitely provide more details about your order.\n",
      "\n",
      "As I mentioned earlier, the status of your order is \"Delivery completed by driver\", which means the package has been successfully delivered to the recipient's address.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You (Customer):  can you check my name or email associated with this order?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Service Agent: I'd be happy to help!\n",
      "\n",
      "According to our records, the order with ID number 1348888 is associated with the recipient's name [Name Not Available]. As for the email address, it's not publicly available due to privacy and security reasons.\n",
      "\n",
      "If you're the recipient or someone authorized to receive that package, please let me know if there's anything else I can help you with!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You (Customer):  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation ended. Thank you!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import faiss\n",
    "from langchain.llms import Ollama\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "\n",
    "# Optional: Environment variables (replace with your preference)\n",
    "local_llm = os.getenv(\"LLM_MODEL\", \"llama3\")  # Default to llama3\n",
    "temperature = float(os.getenv(\"LLM_TEMPERATURE\", 0.1))  # Default temperature of 0.1\n",
    "\n",
    "# Define LLM\n",
    "llama3 = Ollama(model=local_llm)\n",
    "\n",
    "\n",
    "# API endpoint and token\n",
    "api_url = \"http://deliveryapi.piki.co.tz/ordermanager/orders\"\n",
    "api_token = \"eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJodHRwczpcL1wvZGVsaXZlcnlhcGkucGlraS5jby50eiIsImF1ZCI6Imh0dHBzOlwvXC9kZWxpdmVyeWFwaS5waWtpLmNvLnR6IiwiaWF0IjoxNzA4NjA3ODgwLCJuYmYiOjE3MDg2MDc4ODAsImp0aSI6MjQ3ODR9.unjoo_0qMqUDJWKdrh819pRQsJYls05fyUIlx-v6u0c\"  # Replace with your API token\n",
    "\n",
    "\n",
    "def fetch_recent_orders(api_url, api_token, page_size=500):\n",
    "    headers = {\"Authorization\": f\"Bearer {api_token}\"}\n",
    "    params = {\"page_size\": page_size, \"ordering\": \"-created_at\"}\n",
    "    response = requests.get(api_url, headers=headers, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get('results', [])\n",
    "    else:\n",
    "        print(\"Failed to fetch data from API.\")\n",
    "        return []\n",
    "\n",
    "# Fetch recent orders\n",
    "recent_orders = fetch_recent_orders(api_url, api_token)\n",
    "\n",
    "# Check if orders were fetched successfully\n",
    "if recent_orders:\n",
    "    df_orders = pd.DataFrame(recent_orders)\n",
    "else:\n",
    "    print(\"No orders found.\")\n",
    "    exit()\n",
    "\n",
    "class HuggingFaceEmbeddings:\n",
    "    def __init__(self, model_name='sentence-transformers/all-MiniLM-L6-v2'):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "    def encode(self, texts):\n",
    "        inputs = self.tokenizer(texts, return_tensors='pt', padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "    def embed_query(self, query):\n",
    "        encoded_query = self.encode([query])\n",
    "        return encoded_query[0]\n",
    "\n",
    "# Initialize embedding model\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "# Initialize Faiss index\n",
    "embedding_size = embeddings.encode([\"test\"]).shape[1]\n",
    "faiss_index = faiss.IndexFlatL2(embedding_size)\n",
    "\n",
    "# Populate Faiss index with order data\n",
    "order_texts = []\n",
    "order_ids = []\n",
    "for idx, order in df_orders.iterrows():\n",
    "    order_text = f\"Order ID: {order['id']}, Customer: {order['customer']['name']}, Email: {order['customer']['email']}, Total: {order['summary']['total']}, Status: {order['status_info']['name']}\"\n",
    "    order_texts.append(order_text)\n",
    "    order_ids.append(order['id'])\n",
    "    faiss_index.add(embeddings.encode([order_text]))\n",
    "\n",
    "# Define system prompt\n",
    "system_prompt = \"\"\"\n",
    "As a customer service agent for Piki delivery company, \n",
    "be helpful, polite, and understanding. Answer questions to the best of your ability \n",
    "and prioritize customer satisfaction. If you don't know the order details, \n",
    "please say that you don't know. Provide concise and clear responses.\n",
    "\"\"\"\n",
    "\n",
    "# Function to retrieve order details from Faiss index\n",
    "def get_order_details(query, k=1):\n",
    "    query_embedding = embeddings.embed_query(query)\n",
    "    D, I = faiss_index.search(query_embedding.reshape(1, -1), k)\n",
    "    if I[0][0] == -1:\n",
    "        return None\n",
    "    order_id = order_ids[I[0][0]]\n",
    "    return df_orders[df_orders['id'] == order_id].iloc[0]\n",
    "\n",
    "# Session store\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_order_number(query):\n",
    "    \"\"\"Extracts order number from the query using regex.\"\"\"\n",
    "    match = re.search(r'\\b\\d{6,}\\b', query)  # Assuming order numbers are 6 digits or more\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    return None\n",
    "\n",
    "def generate_response(customer_prompt, df_orders, session_id):\n",
    "    chat_history = get_session_history(session_id)\n",
    "    previous_messages = []\n",
    "    for msg in chat_history.messages:\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            previous_messages.append(f\"Human: {msg.content}\")\n",
    "        elif isinstance(msg, AIMessage):\n",
    "            previous_messages.append(f\"AI: {msg.content}\")\n",
    "\n",
    "    prompt = \"\\n\".join(previous_messages) + \"\\n\"\n",
    "    prompt += f\"{system_prompt}\\nCustomer: {customer_prompt}\"\n",
    "\n",
    "    # Check if the customer query includes an order number\n",
    "    order_number = extract_order_number(customer_prompt)\n",
    "\n",
    "    if order_number:\n",
    "        # Fetch order details using the provided order number\n",
    "        matching_order = df_orders[df_orders['id'] == int(order_number)]\n",
    "        if not matching_order.empty:\n",
    "            order_details = matching_order.iloc[0]\n",
    "            order_details_text = (\n",
    "                f\" (Order ID: {order_details['id']}, \"\n",
    "                f\"Customer: {order_details['customer'].get('name', 'N/A')}, \"\n",
    "                f\"Email: {order_details['customer'].get('email', 'N/A')}, \"\n",
    "                f\"Total: {order_details['summary'].get('total', 'N/A')}, \"\n",
    "                f\"Status: {order_details['status_info'].get('name', 'N/A')})\"\n",
    "            )\n",
    "            prompt += f\"\\nOrder Details: {order_details_text}\"\n",
    "        else:\n",
    "            prompt += \"\\nI couldn't find your order details. Please make sure the order number is correct.\"\n",
    "    else:\n",
    "        prompt += \"\\nCould you please provide your order number so I can assist you better?\"\n",
    "\n",
    "    response = llama3.invoke(prompt, temperature=temperature)\n",
    "\n",
    "    # Save current interaction to chat history\n",
    "    chat_history.add_user_message(HumanMessage(content=customer_prompt))\n",
    "    chat_history.add_ai_message(AIMessage(content=response))\n",
    "\n",
    "    return response\n",
    "\n",
    "# Main loop to interact with the customer\n",
    "while True:\n",
    "    customer_prompt = input(\"You (Customer): \")\n",
    "    if customer_prompt.lower() == \"quit\":\n",
    "        print(\"Conversation ended. Thank you!\")\n",
    "        break\n",
    "\n",
    "    session_id = \"default\"  # Use a unique session ID for each session/customer\n",
    "    \n",
    "    # Initial greeting\n",
    "    if customer_prompt.lower() == \"hello\":\n",
    "        print(\"Customer Service Agent: Hello! Thank you for reaching out to Piki delivery company. I'd be happy to help you with your inquiry. However, before we proceed, could you please share the order number or any relevant details about your shipment that you're concerned about? That way, I can better assist you and provide a more personalized solution.\")\n",
    "    else:\n",
    "        response = generate_response(customer_prompt, df_orders, session_id)\n",
    "        print(\"Customer Service Agent:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0084f13-ccb5-4e65-952c-e2143733a16c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9adab3a-d332-4e2e-bd81-f4fc48ae7971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16686398-8edc-45d3-8ea2-efd03b21cf94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8e0402-5d16-4e41-9360-1400fc9293e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6dcfb54-896c-4216-87cb-5abf70015bc3",
   "metadata": {},
   "source": [
    "NEW OPTION WITH MODIFIED COLUMN & FAQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cda26f74-784e-4d5d-a160-f5e3765abc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID CUSTOMER NAME                CUSTOMER EMAIL CUSTOMER CELLPHONE  \\\n",
      "0  1347956      Godson    washingtongadson56@gmail.com               None   \n",
      "1  1345072    Mudassir      mudassirkadri786@gmail.com         0758962905   \n",
      "\n",
      "                                    CUSTOMER ADDRESS DRIVER NAME  \\\n",
      "0                                               None  Machemba     \n",
      "1  Richmond Tower, Mindu Street, Dar es Salaam, T...        None   \n",
      "\n",
      "  DRIVER LASTNAME DRIVER CELLPHONE     BUSINESS NAME  \\\n",
      "0                       0693236427  KFC Mlimani City   \n",
      "1            None             None           Masifio   \n",
      "\n",
      "             BUSINESS EMAIL  ... Promised Completion Time          created_at  \\\n",
      "0     kfctz000000@gmail.com  ...      2024-06-28 00:45:00 2024-06-27 05:44:59   \n",
      "1  masifioestates@gmail.com  ...      2024-06-28 00:45:00 2024-06-23 20:47:51   \n",
      "\n",
      "  business_accepted_at dispatched_at driver_accepted_at driver_arrived_at  \\\n",
      "0                  NaT           NaT                NaT               NaN   \n",
      "1  2024-06-25 18:27:00           NaT                NaT               NaN   \n",
      "\n",
      "  driver_pickup_at delivery_at HOURS                 STATE  \n",
      "0              NaN         NaN     5              Preorder  \n",
      "1              NaN         NaN    20  Accepted by business  \n",
      "\n",
      "[2 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import faiss\n",
    "from langchain.llms import Ollama\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "\n",
    "\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import faiss\n",
    "from langchain.llms import Ollama\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "\n",
    "\n",
    "\n",
    "# API endpoint and token\n",
    "api_url = \"http://deliveryapi.piki.co.tz/ordermanager/orders\"\n",
    "api_token = \"eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJodHRwczpcL1wvZGVsaXZlcnlhcGkucGlraS5jby50eiIsImF1ZCI6Imh0dHBzOlwvXC9kZWxpdmVyeWFwaS5waWtpLmNvLnR6IiwiaWF0IjoxNzA4NjA3ODgwLCJuYmYiOjE3MDg2MDc4ODAsImp0aSI6MjQ3ODR9.unjoo_0qMqUDJWKdrh819pRQsJYls05fyUIlx-v6u0c\"  # Replace with your API token\n",
    "\n",
    "\n",
    "\n",
    "# Function to fetch recent orders from the API\n",
    "def fetch_recent_orders(api_url, api_token, page_size=500):\n",
    "    headers = {\"Authorization\": f\"Bearer {api_token}\"}\n",
    "    params = {\"page_size\": page_size, \"ordering\": \"-created_at\"}\n",
    "    response = requests.get(api_url, headers=headers, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get('results', [])\n",
    "    else:\n",
    "        print(\"Failed to fetch data from API.\")\n",
    "        return []\n",
    "\n",
    "# Function to process orders and return a DataFrame\n",
    "def process_orders(data):\n",
    "    # Define selected columns\n",
    "    selected_columns = ['ID', 'CUSTOMER NAME', 'CUSTOMER EMAIL', 'CUSTOMER CELLPHONE', 'CUSTOMER ADDRESS',\n",
    "                        'DRIVER NAME', 'DRIVER LASTNAME', 'DRIVER CELLPHONE',\n",
    "                        'BUSINESS NAME', 'BUSINESS EMAIL', 'BUSINESS PHONE', 'BUSINESS CELLPHONE', 'BUSINESS ADDRESS',\n",
    "                        'BUSINESS CITY', 'PRODUCTS', 'SUBTOTAL', 'DELIVERY FEE', 'DRIVER TIP', 'TOTAL',\n",
    "                        'DELIVERY DATE', 'DELIVERY TIME', 'MESSAGES',\n",
    "                        'Accepted by Business', 'Assigned Time', 'Accepted by Driver',\n",
    "                        'Driver to Business', 'Driver in Business', 'Pickup to Customer', 'Average Delivery Time',\n",
    "                        'Promised Preparation Time', 'Promised Completion Time', \n",
    "                        'created_at', 'business_accepted_at', 'dispatched_at', 'driver_accepted_at',\n",
    "                        'driver_arrived_at', 'driver_pickup_at', 'delivery_at', 'HOURS', 'STATE']\n",
    "\n",
    "    data_rows = []\n",
    "\n",
    "    for order in data:\n",
    "        time_stats = order.get('time_stats', {})\n",
    "        \n",
    "        created_at = pd.to_datetime(time_stats.get('created_at', None))\n",
    "        business_accepted_at = pd.to_datetime(time_stats.get('business_accepted_at', None))\n",
    "        dispatched_at = pd.to_datetime(time_stats.get('dispatched_at', None))\n",
    "        driver_accepted_at = pd.to_datetime(time_stats.get('driver_accepted_at', None))\n",
    "        driver_at_business_at = pd.to_datetime(time_stats.get('driver_at_business_at', None))\n",
    "        driver_picked_at = pd.to_datetime(time_stats.get('driver_picked_at', None))\n",
    "        delivery_completed_at = pd.to_datetime(time_stats.get('delivery_completed_at', None))\n",
    "        promised_preparation_time = pd.to_datetime(time_stats.get('promised_preparation_time', None))\n",
    "        promised_completion_time = pd.to_datetime(time_stats.get('promised_completion_time', None))\n",
    "\n",
    "        def calculate_duration(start, end):\n",
    "            if pd.notnull(start) and pd.notnull(end):\n",
    "                return (end - start).total_seconds() / 60\n",
    "            return None\n",
    "        \n",
    "        accepted_by_business = calculate_duration(created_at, business_accepted_at)\n",
    "        assigned_time = calculate_duration(created_at, dispatched_at)\n",
    "        accepted_by_driver = calculate_duration(dispatched_at, driver_accepted_at)\n",
    "        driver_to_business = calculate_duration(driver_accepted_at, driver_at_business_at)\n",
    "        driver_in_business = calculate_duration(driver_at_business_at, driver_picked_at)\n",
    "        pickup_to_customer = calculate_duration(driver_picked_at, delivery_completed_at)\n",
    "        average_delivery_time = calculate_duration(created_at, delivery_completed_at)\n",
    "\n",
    "        row_data = {\n",
    "            'ID': order.get('id'),\n",
    "            'CUSTOMER NAME': order.get('customer', {}).get('name'),\n",
    "            'CUSTOMER EMAIL': order.get('customer', {}).get('email'),\n",
    "            'CUSTOMER CELLPHONE': order.get('customer', {}).get('cellphone'),\n",
    "            'CUSTOMER ADDRESS': order.get('customer', {}).get('address'),\n",
    "            'DRIVER NAME': order.get('driver', {}).get('fullname') if order.get('driver') else None,\n",
    "            'DRIVER LASTNAME': order.get('driver', {}).get('last_name') if order.get('driver') else None,\n",
    "            'DRIVER CELLPHONE': order.get('driver', {}).get('cellphone') if order.get('driver') else None,\n",
    "            'BUSINESS NAME': order.get('business', {}).get('name'),\n",
    "            'BUSINESS EMAIL': order.get('business', {}).get('email'),\n",
    "            'BUSINESS PHONE': order.get('business', {}).get('phone'),\n",
    "            'BUSINESS CELLPHONE': order.get('business', {}).get('cellphone'),\n",
    "            'BUSINESS ADDRESS': order.get('business', {}).get('address'),\n",
    "            'BUSINESS CITY': order.get('city', {}).get('name'),\n",
    "            'PRODUCTS': order.get('products'),\n",
    "            'SUBTOTAL': order.get('summary', {}).get('subtotal'),\n",
    "            'DELIVERY FEE': order.get('summary', {}).get('delivery_price'),\n",
    "            'DRIVER TIP': order.get('summary', {}).get('driver_tip'),\n",
    "            'TOTAL': order.get('summary', {}).get('total'),\n",
    "            'DELIVERY DATE': created_at.strftime('%Y/%m/%d') if created_at else None,\n",
    "            'DELIVERY TIME': created_at.strftime('%H:%M:%S') if created_at else None,\n",
    "            'MESSAGES': order.get('messages'),\n",
    "            'Accepted by Business': accepted_by_business,\n",
    "            'Assigned Time': assigned_time,\n",
    "            'Accepted by Driver': accepted_by_driver,\n",
    "            'Driver to Business': driver_to_business,\n",
    "            'Driver in Business': driver_in_business,\n",
    "            'Pickup to Customer': pickup_to_customer,\n",
    "            'Average Delivery Time': average_delivery_time,\n",
    "            'Promised Preparation Time': promised_preparation_time,\n",
    "            'Promised Completion Time': promised_completion_time,\n",
    "            'created_at': created_at,\n",
    "            'business_accepted_at': business_accepted_at,\n",
    "            'dispatched_at': dispatched_at,\n",
    "            'driver_accepted_at': driver_accepted_at,\n",
    "            'driver_arrived_at': driver_in_business,\n",
    "            'driver_pickup_at': pickup_to_customer,\n",
    "            'delivery_at': average_delivery_time,\n",
    "            'HOURS': created_at.hour if created_at else None,\n",
    "            'STATE': order.get('status_info', {}).get('name')\n",
    "        }\n",
    "\n",
    "        data_rows.append(row_data)\n",
    "\n",
    "    df = pd.DataFrame(data_rows, columns=selected_columns)\n",
    "    return df\n",
    "\n",
    "# Fetch recent orders\n",
    "recent_orders = fetch_recent_orders(api_url, api_token)\n",
    "\n",
    "# Process orders into a DataFrame\n",
    "if recent_orders:\n",
    "    df_orders = process_orders(recent_orders)\n",
    "else:\n",
    "    print(\"No orders found.\")\n",
    "    exit()\n",
    "\n",
    "# Now df_orders contains the processed data in the desired format\n",
    "print(df_orders.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa337da-5ae6-4c3e-8967-99abd272ca69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587444be-f74a-4dbe-b907-911c4bcdface",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e843b28-1b78-4d19-9134-dcfb63ebd31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SKIP tHIS PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65600cb3-25f4-4b54-b8f2-d85d5640c6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: faiss-cpu in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (1.8.0.post1)\n",
      "Requirement already satisfied: torch in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: transformers in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (4.41.2)\n",
      "Requirement already satisfied: langchain in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (0.2.3)\n",
      "Requirement already satisfied: sentence-transformers in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: packaging in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from faiss-cpu) (23.2)\n",
      "Requirement already satisfied: filelock in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from torch) (2024.6.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from transformers) (0.23.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (0.2.6)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (0.2.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (0.1.77)\n",
      "Requirement already satisfied: pydantic<3,>=1 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (2.7.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain) (8.3.0)\n",
      "Requirement already satisfied: scikit-learn in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from sentence-transformers) (1.5.0)\n",
      "Requirement already satisfied: scipy in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: Pillow in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.5)\n",
      "Requirement already satisfied: intel-openmp==2021.* in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.13.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
      "Requirement already satisfied: six>=1.5 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from requests->transformers) (2024.6.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: colorama in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\programs\\anaconda3\\envs\\llm\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (3.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas faiss-cpu torch transformers langchain sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c398db5-460f-4207-8e63-9c10bbf0bbab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7ccd8bb-5c0a-4b39-883e-357233990567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import faiss\n",
    "import torch\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#from langchain.chat_models import Ollama\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "\n",
    "\n",
    "# Define initial greetings and welcoming messages\n",
    "initial_greetings = [\n",
    "    \"hello\", \"hi\", \"hey\", \"morning\", \"mambo\", \"vip\", \"habari\", \"hi piki\",\n",
    "    \"good morning\", \"good afternoon\", \"good evening\", \"hello there\", \"hey there\",\n",
    "    \"greetings\", \"salutations\", \"hi there\"\n",
    "]\n",
    "\n",
    "welcoming_messages = [\n",
    "    \"Hello! Thank you for reaching out to Piki delivery company. I'd be happy to help you with your inquiry. However, before we proceed, could you please share the order number or any relevant details about your shipment that you're concerned about? That way, I can better assist you and provide a more personalized solution.\",\n",
    "    \"Hi there! Welcome to Piki delivery company. How can I assist you today?\",\n",
    "    \"Greetings! Thank you for contacting Piki delivery company. How can I help you with your delivery needs today?\",\n",
    "    \"Hello! We're glad you reached out to Piki delivery company. How may I assist you today?\",\n",
    "    \"Hi! Thank you for choosing Piki delivery company. What can I do for you today?\",\n",
    "    \"Hey there! Need help with something? Piki delivery company is here for you.\",\n",
    "    \"Hi! How can I make your day easier with Piki delivery company services?\",\n",
    "    \"Hello! Thanks for getting in touch with Piki delivery company. Do you need help with a recent order or have any questions?\",\n",
    "    \"Hi! It's great to hear from you. How can I assist you with your delivery today?\",\n",
    "    \"Hello! Thank you for reaching out. How can I assist you with your delivery? Please let me know your order number or any details you have.\",\n",
    "    \"Hi there! I’m here to help with any questions or concerns you have about your delivery. How can I assist you today?\"\n",
    "]\n",
    "\n",
    "\n",
    "# FAQ dictionary\n",
    "faqs = {\n",
    "    \"about piki\": \"Piki is the most convenient online ordering site in Tanzania, connecting people with the best goods, services and restaurants around them. We believe ordering goods, services or food should be a pleasure and should be a quick, painless, and even fun experience. Ordering with Piki is done in a few easy steps: 1- Create an account using your email and phone number and add your delivery location so that we can link you to the services available in your area 2 - Select the service type that you require, be it food, groceries, drinks, general shopping or another service. 3 - Browse or search for the product or services that you need, and add the orders to your cart 4 - Place the order, being careful to select the right payment type and delivery location 5 - Receive your good or service at your doorstep! Your order will be delivered to you in no time 6 - Enjoy your order, and if you have any queries or feedback (Good or Bad!) please feel free to contact us at service@piki.co.tz or call 0659 077 007 On your mobile, tablet, desktop or via our app, Piki is a delicious experience!\",\n",
    "    \"how do i place an order\": \"Once you have the Piki application from Google Playstore or Apple Appstore, or are on the Piki website, please follow the following steps: 1. Choose your location (more details below) 2. Select the category of order you would like to make (Food, Drinks, Groceries, Other) 3. Select the vendor that you wish to order from (either scroll down or search by vendor name) 4. Select the item/s you wish to order from that vendor, including any required add-ons 5. Checkout, and wait for your order to arrive 6. Pay on delivery and enjoy your orders!\",\n",
    "    \"how do i know if my order is being processed\": \"Once your order is placed, you will receive a confirmation email. If you registered an account with Piki, you can also check the status of your order in the Piki application by clicking the menu button in the top left, and selecting ‘My Orders’.\",\n",
    "    \"why did i not receive a call to confirm my order\": \"New customers will normally receive a call to confirm the order and to confirm the delivery location. However, once the Piki team has delivered to your location successfully, in general orders can be processed without the need to call to confirm. If you need to discuss anything about your orders, please contact our customer service team.\",\n",
    "    \"can i cancel or change my order\": \"If you wish to cancel your order, you must try to contact Piki as soon after you place the order as possible, as once the restaurant has accepted and started to prepare the order, it will not be able to be cancelled. Please reply to your confirmation email at service@piki.co.tz, or call the customer service line on 0659077007.\",\n",
    "    \"how can i make payment\": \"Currently, you can pay the delivery driver either by mobile money or with cash. Online card and mobile payment options will be available soon.\",\n",
    "    \"what do i do if there is a problem with my order\": \"At Piki, we strive to deliver the best possible eat-out experience to all of our customers. If you have any issues with the order, whether with the food quality, the packaging, the delivery service provider, or anything else, please do not hesitate to contact our customer service team at service@piki.co.tz or 0659077007 and we will do everything we can to resolve your issue.\",\n",
    "    \"i’m having problems setting my delivery address\": \"Unfortunately, Google Maps does not recognize all Tanzanian addresses, so it sometimes does not allow your street name or the number of your house in the address field. If the address that shows when you click the pin locate button, is not correct, or an address does not show, please type in a nearby area, for example, ‘Masaki, Dar es Salaam’, or a nearby street. Google Maps should recognize this area, but will most likely move the pin away from where you are exactly located. Please manually scroll the map so that the pin is in your exact location, and then fill out the ‘Delivery Instructions’ field, with precise instructions to assist the driver to find your location, including the property number, and physical description and nearby landmarks. For example, “House number 17, which 3 houses past the Church if you are coming from the main road, on your right, with a red gate. Please speak to the askari who will tell you where to deliver.” What is important for Piki, is that the Pin that you mark on the map is the correct location, and that the delivery instructions field is filled out with enough details to assist the driver to locate you, and what he should do when he arrives.\",\n",
    "    \"why is the app not allowing me to check-out\": \"In most cases, this will be relating to the delivery address - if the address does not have delivery instructions or another field is not filled correctly, you will not be able to check out. If everything is filled correctly, and it still does not work, please close the application completely, open it again and try again. If this still does not work, please call our customer service team for assistance on 0659077007.\",\n",
    "    \"how do i give feedback\": \"At Piki, we LOVE to receive feedback from our customers (good or bad!), as it encourages us when we have got it right and helps us to learn if there is anything we could have done better. As the entirety of the service happens out of sight of the management team, our customers’ feedback is the only way we can know if our team are doing a great job or not. In the menu button on the app, please click ‘My Orders’ and on each order, you can leave feedback on the service. If you would like to give more feedback or engage with our team, please email service@piki.co.tz.\"\n",
    "}\n",
    "\n",
    "# Environment variables (replace with your preference)\n",
    "local_llm = \"llama3\"  # Default to llama3\n",
    "temperature = 0.1  # Default temperature of 0.1\n",
    "\n",
    "# Define LLM\n",
    "llama3 = Ollama(model=local_llm) \n",
    "\n",
    "\n",
    "# HuggingFaceEmbeddings class\n",
    "class HuggingFaceEmbeddings:\n",
    "    def __init__(self, model_name='sentence-transformers/all-MiniLM-L6-v2'):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "    def encode(self, texts):\n",
    "        inputs = self.tokenizer(texts, return_tensors='pt', padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "    def embed_query(self, query):\n",
    "        encoded_query = self.encode([query])\n",
    "        return encoded_query[0]\n",
    "\n",
    "# Initialize embedding model\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "# Initialize Faiss index\n",
    "embedding_size = embeddings.encode([\"test\"]).shape[1]\n",
    "faiss_index = faiss.IndexFlatL2(embedding_size)\n",
    "\n",
    "# Load data\n",
    "df_orders = pd.DataFrame({\n",
    "    'ID': [1, 2],\n",
    "    'CUSTOMER NAME': ['John Doe', 'Jane Smith'],\n",
    "    'CUSTOMER EMAIL': ['john.doe@example.com', 'jane.smith@example.com'],\n",
    "    'TOTAL': [100.0, 200.0],\n",
    "    'STATE': ['Processed', 'Pending']\n",
    "})\n",
    "\n",
    "# Populate Faiss index with order data\n",
    "order_texts = []\n",
    "order_ids = []\n",
    "for idx, order in df_orders.iterrows():\n",
    "    order_text = f\"Order ID: {order['ID']}, Customer: {order['CUSTOMER NAME']}, Email: {order['CUSTOMER EMAIL']}, Total: {order['TOTAL']}, Status: {order['STATE']}\"\n",
    "    order_texts.append(order_text)\n",
    "    order_ids.append(order['ID'])\n",
    "    faiss_index.add(embeddings.encode([order_text]))\n",
    "\n",
    "# Preprocess text\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# Embed FAQs\n",
    "faq_embeddings = {question: embeddings.embed_query(preprocess_text(question)) for question in faqs.keys()}\n",
    "\n",
    "\n",
    "# Find most similar FAQ\n",
    "def find_similar_faq(query):\n",
    "    query_embedding = embeddings.embed_query(preprocess_text(query))\n",
    "    similarities = {question: cosine_similarity([query_embedding], [embedding])[0][0] for question, embedding in faq_embeddings.items()}\n",
    "    most_similar_question = max(similarities, key=similarities.get)\n",
    "    if similarities[most_similar_question] > 0.7:  # Similarity threshold\n",
    "        return faqs[most_similar_question]\n",
    "    return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f102f44-efb4-4b36-a383-3529a6c03e36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ad2433a-8763-4fd9-90cd-319988b62ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You (Customer):  hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Service Agent: Hi! Thank you for choosing Piki delivery company. What can I do for you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You (Customer):  can you please check my order details?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Service Agent: I'd be happy to help you with that! To access your order details, I'll need the order number associated with your delivery. Could you please share it with me? That way, I can look into the specifics of your order and provide you with accurate information.\n",
      "\n",
      "If you're not sure what your order number is, don't worry! We can try to locate it for you. Can you tell me a little bit more about your order, such as the date you placed it or any other relevant details?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You (Customer):  1348888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Service Agent: Thank you for providing the order number! I've checked our system, but unfortunately, it seems like we can't locate any information related to order number 1348888. Could you please double-check the order number or provide more context about your delivery? Was it a recent order or did you place it some time ago? Any additional details you can share might help me better assist you in finding the correct information.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You (Customer):  how to place order?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Service Agent: I'd be happy to help! However, since you're asking about placing an order, it seems like we haven't started the process yet. To place an order with Piki delivery company, you can follow these simple steps:\n",
      "\n",
      "1. Visit our website and navigate to the \"Order\" section.\n",
      "2. Choose your preferred delivery option (date, time, etc.).\n",
      "3. Select the items you'd like to receive from our menu or catalog.\n",
      "4. Review your order summary to ensure everything is correct.\n",
      "5. Proceed to checkout and provide your payment information.\n",
      "\n",
      "If you have any questions or need assistance during this process, please don't hesitate to ask!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You (Customer):  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation ended. Thank you!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "system_prompt = \"\"\"\n",
    "As a customer service agent for Piki delivery company, \n",
    "be helpful, polite, and understanding. Answer questions to the best of your ability \n",
    "and prioritize customer satisfaction. If you don't know the order details, \n",
    "please say that you don't know. Provide concise and clear responses.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Function to retrieve order details from Faiss index\n",
    "def get_order_details(query, k=1):\n",
    "    query_embedding = embeddings.embed_query(query)\n",
    "    D, I = faiss_index.search(query_embedding.reshape(1, -1), k)\n",
    "    if I[0][0] == -1:\n",
    "        return None\n",
    "    order_id = order_ids[I[0][0]]\n",
    "    return df_orders[df_orders['ID'] == order_id].iloc[0]\n",
    "\n",
    "# Session store\n",
    "store = {}\n",
    "\n",
    "# Extract order number from customer query\n",
    "def extract_order_number(prompt):\n",
    "    match = re.search(r'\\b\\d+\\b', prompt)\n",
    "    return match.group() if match else None\n",
    "\n",
    "# Generate response to customer query\n",
    "def generate_response(customer_prompt, df_orders, session_id):\n",
    "    # Check for FAQs first\n",
    "    for question, answer in faqs.items():\n",
    "        if question.lower() in customer_prompt:\n",
    "            return answer\n",
    "\n",
    "    chat_history = get_session_history(session_id)\n",
    "    previous_messages = []\n",
    "    for msg in chat_history.messages:\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            previous_messages.append(f\"Human: {msg.content}\")\n",
    "        elif isinstance(msg, AIMessage):\n",
    "            previous_messages.append(f\"AI: {msg.content}\")\n",
    "\n",
    "    prompt = \"\\n\".join(previous_messages) + \"\\n\"\n",
    "    prompt += f\"{system_prompt}\\nCustomer: {customer_prompt}\"\n",
    "\n",
    "    # Check if the customer query includes an order number\n",
    "    order_number = extract_order_number(customer_prompt)\n",
    "\n",
    "    if order_number:\n",
    "        # Fetch order details using the provided order number\n",
    "        matching_order = df_orders[df_orders['ID'] == int(order_number)]\n",
    "        if not matching_order.empty:\n",
    "            order_details = matching_order.iloc[0]\n",
    "            order_details_text = (\n",
    "                f\" (Order ID: {order_details['ID']}, \"\n",
    "                f\"Customer: {order_details['CUSTOMER NAME']}, \"\n",
    "                f\"Email: {order_details['CUSTOMER EMAIL']}, \"\n",
    "                f\"Total: {order_details['TOTAL']}, \"\n",
    "                f\"Status: {order_details['STATE']})\"\n",
    "            )\n",
    "            prompt += f\"\\nOrder Details: {order_details_text}\"\n",
    "        else:\n",
    "            prompt += \"\\nI couldn't find your order details. Please make sure the order number is correct.\"\n",
    "    else:\n",
    "        prompt += \"\\nCould you please provide your order number so I can assist you better?\"\n",
    "\n",
    "    response = llama3.invoke(prompt, temperature=temperature)\n",
    "\n",
    "    # Save current interaction to chat history\n",
    "    chat_history.add_user_message(HumanMessage(content=customer_prompt))\n",
    "    chat_history.add_ai_message(AIMessage(content=response))\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "# Main loop to interact with the customer\n",
    "while True:\n",
    "    customer_prompt = input(\"You (Customer): \").strip().lower()\n",
    "    if customer_prompt.lower() == \"quit\":\n",
    "        print(\"Conversation ended. Thank you!\")\n",
    "        break\n",
    "\n",
    "    session_id = \"default\"  # Use a unique session ID for each session/customer\n",
    "\n",
    "    # Check for initial greeting\n",
    "    if any(greeting in customer_prompt for greeting in initial_greetings):\n",
    "        welcoming_message = random.choice(welcoming_messages)\n",
    "        print(f\"Customer Service Agent: {welcoming_message}\")\n",
    "    else:\n",
    "        response = generate_response(customer_prompt, df_orders, session_id)\n",
    "        print(\"Customer Service Agent:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46449285-fc86-4ad2-876c-19d310821695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6272721a-07c4-4b10-8ac0-a96894b87254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e635ed8f-0fbe-47f8-b99b-d8733b94336c",
   "metadata": {},
   "source": [
    "CONTINUE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8552c56-6631-40bc-969c-6a9fd16090cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e209ce-ed11-4ed5-983b-b42b0775adc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b81bd32-4f20-4ad6-9e08-1c0fdc90c835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b520c1d-6553-43e8-9bc5-715ac4d7093f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7e55a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
